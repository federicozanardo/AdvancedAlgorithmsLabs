\section{Descrizione degli algoritmi}

\subsection{Struttura dati per il grafo}

\subsubsection{Introduzione}

Il TSP prende in input un grafo \textit{completo}, ovvero, un grafo in cui:
\[
    \forall u, v \in V \textnormal{ } \exists (u, v) \in E
\]
Il grafo in questione viene definito \textit{denso} e la struttura dati indicata per rappresentarlo è
la \textit{matrice di adiacenza}, di dimensione $|V| \times |V|$. Le celle della matrice contengono
i pesi dei lati che congiungono i due vertici.

La struttura dati per il grafo è stata implementata nel seguente
modo:

\subsubsection{Implementazione}

\subsection{Held e Karp}

\subsubsection{Introduzione}

L'algoritmo di Held and Karp è un algoritmo di programmazione dinamica che permette di determinare in modo esatto il risultato di TSP sfruttando la scomposizione del problema in sotto-problemi e in sotto-sotto-problemi che vengono ricorsivamente risolti. Per ciascun sotto-problema viene generato un risultato che viene salvato all'interno di una tabella contenente tutte le soluzioni che portano poi alla determinazione del cammino minimo di TSP.

L'algoritmo si basa sulla proprietà secondo la quale ogni sottocammino di un cammino minimo è a sua volta un cammino minimo, e ciò ci permette di calcolare i sottoproblemi ricorsivamente nel seguente modo: 

\begin{itemize}
    \item  pongo \(1 ... n\) città (i.e. nodi) da visitare;
    \item  pongo \(S \subseteq V\) e \(v \in S\), dove \(V\) sono le tutte le città in esame, \(S\) le città visitate fino a quel momento e \(v\) la città corrente;

\item definisco \(d[v, S]\) peso del cammino minimo nella città \(v\) a partire dalla città 1 percorrendo \(S\) città;
\item definisco \(\pi[v, S]\) predecessore di \(v\) nel cammino minimo percorrendo \(S\) città.
\end{itemize}

L'esecuzione dell'algoritmo a partire dalla città \(1\) visitando tutti i nodi \(S\) porterà al risultato del cammino minimo che sarà contenuto nel vettore \(d[1, S]\), ripercorribile poi con il vettore \(\pi\). Chiaramente questo tipo di algoritmo esegue in modalità \textit{brute force} tutte le possibili soluzioni e restituisce il cammino minimo una volta raccolti tutti i possibili cammini.

\subsubsection{Algoritmo}

Il seguente psuedocodice mostra la funzione HK-INIT utilizzata per l'inizializzazione dei vettori e del tempo iniziale. 
\begin{verbatim}
HK-INIT(G)
    (V,E) = G
    d = NULL
    pi = NULL
    global_time_start = time.now
    return HK-VISIT(0,V)
\end{verbatim}    

Lo pseudocodice della funzione HK-VISIT mostra esattamente i casi base e i casi ricorsivi per la risoluzione del problema in modo ricorsivo sfruttando l'algoritmo di Held and Karp.
\begin{verbatim}
HK-VISIT(v,S)
    // Caso base 1: ritorno il peso dell'arco {v,0}
    if len(S) = 1 and S = {v} then 
        return w[v,0]
    // Caso base 2: se la distanza è già stata calcolata, ritorno peso dell'arco
    else if d[v,S] is not empty then 
        return d[v,S]
    // Caso ricorsivo: cerco il cammino minimo tra tutti i sottocammini
    else
        mindist = inf
        minprec = NULL
        for all u in S \ {v} do
            if time.now - global_time_start < 180 then
                dist = HK-VISIT(u,S \ {v})
                if dist + w[u, v] < mindist then
                    mindist = dist + w[u, v]
                    minprec = u
                end if
            else
                return mindist
            end if
        end for
        d[v,S] = mindist
        pi[v,S] = minprec
        return mindist
    end if
\end{verbatim}


\subsubsection{Implementazione}

L'implementazione dell'algoritmo è stata strutturata in modo tale che fosse a partire da una visita in profondità (dall'alto) mediante l'uso di due funzioni principali \texttt{hk\_init} e \texttt{hk\_visit}. 

\subsubsection{Ottimizzazioni implementate}

\subsection{Nearest Neighbor}

\subsubsection{Introduzione}

\subsubsection{Implementazione}

\subsubsection{Ottimizzazioni implementate}

\subsection{2-approssimato}

\subsubsection{Introduzione}

L'algoritmo 2-approssimato è in grado di determinare un'approssimazione del TSP sotto la condizione che le
distanze rispettino la \textit{disuguaglianza triangolare}, ovvero:
\begin{equation}
    \forall u, v, w \in V, \textnormal{ vale che } c(u, v) \le c(u, w) + c(w, v)
\end{equation}

dove $c$ è la \textit{funzione di costo}. Questo implica che il cammino con un lato $c(u, v)$ ha un costo
minore o uguale al costo del cammino con due lati $c(u, w, v)$. Il nome di questo problema è \textbf{TRIANGLE\_TSP}.

\subsubsection{Definizione di MST}

Sia $V$ l'insieme dei nodi che costituiscono il grafo pesato $G$ e sia $E$ la collezione dei lati di tale
grafo. Ai fini delle analisi della complessità degli algoritmi, sia $|V| = n$ e $|E| = m$.

Un \textit{minimum spanning tree} è un
sottoinsieme dei lati $E$ di un grafo $G$ non orientato connesso e pesato sui lati che
collega tutti i vertici insieme, senza alcun ciclo e con il minimo peso totale del
lato possibile. Cioè, è uno spanning tree la cui somma dei pesi dei bordi è la più
piccola possibile.

Un \textit{minimum spanning tree} $T = (V, E')$ è un albero, il cui insieme dei lati $E'$ è un
sottoinsieme dei lati $E$ di un grafo $G = (V, E)$ non orientato, connesso e
pesato, che collega tutti i vertici $V$, la cui somma dei pesi dei lati è la minima.

L'algoritmo generico per determinare un MST è:
\begin{verbatim}
    A = empty_set
    while A doesn't form a spanning tree
        find an edge (u,v) that is safe for A
        A = A U {(u,v)}
    return A
\end{verbatim}

Si forniscono alcune definizioni per gli MST:
\begin{enumerate}
    \item un \textbf{taglio} $(S, V \setminus S)$ di un grafo $G = (V, E)$ è una partizione
    di $V$;
    \item un lato $(u, v) \in E$ \textbf{attraversa il taglio} $(S, V \setminus S)$ se
    $u \in S$ e $v \in V \setminus S$ o viceversa;
    \item un taglio \textbf{rispetta} un insieme $A$ di lati se nessun lato di $A$ attraversa
    il taglio;
    \item dato un taglio, il lato che lo attraversa di peso minimo si chiama \textbf{light edge}.
\end{enumerate}

Per determinare se un lato è \textbf{safe}, si sfrutta il seguente teorema:

\textbf{Teorema}: Sia $G = (V, E)$ un grafo non diretto, connesso e pesato. Sia $A$ un
sottoinsieme di $E$ incluso in una qualche MST di $G$, sia $(S, V \setminus S)$ un
taglio che rispetta $A$, e sia $(u, v)$ un \textit{light edge} per $(S, V \setminus S)$.
Allora $(u, v)$ è \textit{safe} per $A$.

\subsubsection{Algoritmo}

L'idea che sta dietro a questo algoritmo consiste nell'utilizzare un algoritmo per il calcolo
del MST. Tuttavia, il MST è un albero e quello che vogliamo ottenere invece è un
ciclo hamiltoniano. Per fare ciò, eseguiamo una visita in \textit{preorder} del MST
e aggiungiamo la radice di tale MST alla lista della determinata dalla preorder. Questo è un ciclo
hamiltoniano del grafo originale, in quanto quest'ultimo è completo. Pertanto, esiste sempre un
lato tra ogni coppia di vertici.

\begin{verbatim}
    2-APPROXIMATION(G=(V,E), c)
        root <- v1 in V         // scelgo un nodo di V come radice per Prim
        T <- Prim(G, c, root)
        H' <- preorder(root)    // visita in preorder
        H <- H U {root}           // aggiungo il percorso che va dalll'ultimo nodo
                                // della visita in preorder alla radice
        return H

\end{verbatim}

\subsubsection{Analisi della qualità della soluzione}

Si illustri l'analisi della qualità della soluzione ritornata dall'algoritmo:
\begin{enumerate}
    \item Il costo di $H'$ è basso per la definizione di MST;
    \item supponiamo che presi due vertici $a$ e $b$ non siano collegati da un lato (anche se
    sappiamo che il grafo è completo), L'idea è che il costo di $(a, b)$ è minore rispetto
    al costo di fare un giro più largo, in quanto vale la \textit{disuguaglianza triangolare}.
    Quindi in questo caso $(a, b)$ è un \textit{shortcut}.
\end{enumerate}

\subsubsection{Analisi del fattore di approssimazione}
Si illustri l'analisi del fattore di approssimazione dell'algoritmo:
\begin{enumerate}
    \item \textit{Limite inferiore al costo della soluzione ottima $H$}: sia $H$ il ciclo
    ottimo $H^{ottimo} = <v_{j1}, ..., v_{jn}, v_{j1}>$.
    Sia $H'^{ottimo} = <v_{j1}, ..., v_{jn}>$ un cammino
    (è uno spanning tree, non un ciclo) hamiltoniano. Quindi, $c(H') \ge c(T)$, dove $T$ è
    il MST, e $c(H^{ottimo}) \ge c(H'^{ottimo})$ prechè i costi sono maggiori o uguali a zero.

    \item \textit{Limite superiore al costo della soluzione restituita $H$}: dato un albero,
    una \textit{full preorder chain} è una lista con ripetizioni dei nodi dell'albero che
    indica i nodi raggiunti dalle chiamate ricorsive dell'algoritmo \verb|Preorder|.

    \textit{Proprietà}: in una full preorder chain ogni arco di $T$ appare esattamente due
    volte. Quindi $c(\textnormal{full preorder chain}) = 2 \cdot c(T)$. Se si eliminano
    dalla full preorder chain tutte le occorrenze successive alla prima dei nodi interni
    (tranne l'ultima occorrenza della radice) otteniamo, grazie alla
    \textit{disuguaglianza triangolare}:
    \[
        2 \cdot c(T) \ge c(H) \Rightarrow 2 \cdot c(H^{ottimo}) \ge 2 \cdot c(T) \ge c(H)
        \Rightarrow \frac{c(H)}{c(H^{ottimo})} \le 2
    \]

\end{enumerate}

\subsubsection{Implementazione}

\subsubsection{Ottimizzazioni implementate}

